{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc56c3b5",
   "metadata": {},
   "source": [
    "# üöÄ Modelo de Clasificaci√≥n - Odisea C√≥smica\n",
    "\n",
    "**Objetivo**: Predecir si los pasajeros fueron transportados durante la ruptura espacio-tiempo.\n",
    "\n",
    "**M√©trica de Evaluaci√≥n**: Accuracy (Exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56254816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar visualizaciones\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "%matplotlib inline\n",
    "\n",
    "print('‚úì Librer√≠as cargadas exitosamente')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de699ec0",
   "metadata": {},
   "source": [
    "# PASO 1: An√°lisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee2c5d",
   "metadata": {},
   "source": [
    "## 1.1 Carga e Inspecci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('registros_entrenamiento-2.csv')\n",
    "\n",
    "print('INFORMACI√ìN GENERAL DEL DATASET')\n",
    "print('=' * 70)\n",
    "print(f'Dimensiones: {df.shape[0]} filas √ó {df.shape[1]} columnas')\n",
    "print(f'\\nTipos de datos:')\n",
    "print(df.dtypes)\n",
    "print(f'\\nValores faltantes:')\n",
    "print(df.isnull().sum())\n",
    "print(f'\\nEstad√≠sticas descriptivas:')\n",
    "display(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5cecb",
   "metadata": {},
   "source": [
    "## 1.2 An√°lisis de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4308131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('AN√ÅLISIS DE VALORES FALTANTES')\n",
    "print('=' * 70)\n",
    "\n",
    "# Contar nulos por columna\n",
    "nulos = df.isnull().sum()\n",
    "nulos_pct = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "faltantes = pd.DataFrame({\n",
    "    'Columna': nulos.index,\n",
    "    'Nulos': nulos.values,\n",
    "    'Porcentaje': nulos_pct.values\n",
    "}).sort_values('Nulos', ascending=False)\n",
    "\n",
    "print(faltantes[faltantes['Nulos'] > 0])\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(10, 6))\n",
    "faltantes_viz = faltantes[faltantes['Nulos'] > 0]\n",
    "plt.barh(faltantes_viz['Columna'], faltantes_viz['Porcentaje'], color='coral')\n",
    "plt.xlabel('Porcentaje de Valores Faltantes (%)')\n",
    "plt.title('An√°lisis de Valores Faltantes por Columna')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721673f2",
   "metadata": {},
   "source": [
    "## 1.3 Distribuci√≥n de la Variable Objetivo (Transportado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b31446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('DISTRIBUCI√ìN DE TRANSPORTADO')\n",
    "print('=' * 70)\n",
    "\n",
    "transportado_counts = df['Transportado'].value_counts()\n",
    "transportado_pct = df['Transportado'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(transportado_counts)\n",
    "print(f'\\nPorcentajes:')\n",
    "print(transportado_pct)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Gr√°fico de barras\n",
    "axes[0].bar(['No Transportado', 'Transportado'], transportado_counts.values, color=['#FF6B6B', '#4ECDC4'])\n",
    "axes[0].set_ylabel('Cantidad')\n",
    "axes[0].set_title('Distribuci√≥n de Transportado (Frecuencia)')\n",
    "for i, v in enumerate(transportado_counts.values):\n",
    "    axes[0].text(i, v + 20, str(v), ha='center')\n",
    "\n",
    "# Gr√°fico de pastel\n",
    "axes[1].pie(transportado_counts.values, labels=['No Transportado', 'Transportado'], autopct='%1.1f%%', colors=['#FF6B6B', '#4ECDC4'])\n",
    "axes[1].set_title('Distribuci√≥n de Transportado (Proporci√≥n)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabdfff1",
   "metadata": {},
   "source": [
    "## 1.4 Distribuci√≥n de Variables Num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db542f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('AN√ÅLISIS DE VARIABLES NUM√âRICAS')\n",
    "print('=' * 70)\n",
    "\n",
    "# Identificar columnas num√©ricas\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "# Excluir Transportado si est√° incluida\n",
    "if 'Transportado' in num_cols:\n",
    "    num_cols.remove('Transportado')\n",
    "\n",
    "print(f'Variables num√©ricas ({len(num_cols)}): {num_cols}')\n",
    "\n",
    "# Visualizar histogramas\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(num_cols[:9]):\n",
    "    axes[idx].hist(df[col].dropna(), bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'{col}')\n",
    "    axes[idx].set_xlabel('Valor')\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "\n",
    "for idx in range(len(num_cols[:9]), 9):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc36959",
   "metadata": {},
   "source": [
    "## 1.5 Distribuci√≥n de Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5990e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('AN√ÅLISIS DE VARIABLES CATEG√ìRICAS')\n",
    "print('=' * 70)\n",
    "\n",
    "# Identificar columnas categ√≥ricas\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f'Variables categ√≥ricas ({len(cat_cols)}): {cat_cols}')\n",
    "\n",
    "# Visualizar distribuciones\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(cat_cols[:6]):\n",
    "    counts = df[col].value_counts()\n",
    "    axes[idx].barh(counts.index[:10], counts.values[:10], color='mediumpurple')\n",
    "    axes[idx].set_title(f'{col} (top 10)')\n",
    "    axes[idx].set_xlabel('Cantidad')\n",
    "\n",
    "for idx in range(len(cat_cols[:6]), 6):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d900a7",
   "metadata": {},
   "source": [
    "print('AN√ÅLISIS DE CORRELACIONES')\n",
    "print('=' * 70)\n",
    "\n",
    "# Correlaci√≥n de variables num√©ricas\n",
    "# Convertir Transportado a num√©rico temporalmente para correlaci√≥n\n",
    "df_corr = df.copy()\n",
    "df_corr['Transportado'] = df_corr['Transportado'].astype(int)\n",
    "num_cols_all = df_corr.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "correlaciones = df_corr[num_cols_all].corr()['Transportado'].sort_values(ascending=False)\n",
    "\n",
    "print('\\nTop 10 correlaciones con Transportado:')\n",
    "print(correlaciones.head(11))  # 11 para excluir Transportado mismo\n",
    "\n",
    "# Visualizar correlaciones\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_corr = correlaciones.head(11)[1:]  # Excluir Transportado\n",
    "plt.barh(range(len(top_corr)), top_corr.values, color=['green' if x > 0 else 'red' for x in top_corr.values])\n",
    "plt.yticks(range(len(top_corr)), top_corr.index)\n",
    "plt.xlabel('Correlaci√≥n con Transportado')\n",
    "plt.title('Top 10 Variables Correlacionadas con Transportado')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mapa de calor de correlaciones\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df_corr[num_cols_all].corr(), cmap='coolwarm', center=0, annot=False)\n",
    "plt.title('Matriz de Correlaci√≥n - Variables Num√©ricas')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd991ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('AN√ÅLISIS DE CORRELACIONES')\n",
    "print('=' * 70)\n",
    "\n",
    "# Correlaci√≥n de variables num√©ricas\n",
    "num_cols_all = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "correlaciones = df[num_cols_all].corr()['Transportado'].sort_values(ascending=False)\n",
    "\n",
    "print('\\nTop 10 correlaciones con Transportado:')\n",
    "print(correlaciones.head(11))  # 11 para excluir Transportado mismo\n",
    "\n",
    "# Visualizar correlaciones\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_corr = correlaciones.head(11)[1:]  # Excluir Transportado\n",
    "plt.barh(range(len(top_corr)), top_corr.values, color=['green' if x > 0 else 'red' for x in top_corr.values])\n",
    "plt.yticks(range(len(top_corr)), top_corr.index)\n",
    "plt.xlabel('Correlaci√≥n con Transportado')\n",
    "plt.title('Top 10 Variables Correlacionadas con Transportado')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mapa de calor de correlaciones\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[num_cols_all].corr(), cmap='coolwarm', center=0, annot=False)\n",
    "plt.title('Matriz de Correlaci√≥n - Variables Num√©ricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dca357",
   "metadata": {},
   "source": [
    "## 1.7 Hallazgos Clave y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c90451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('RESUMEN DE HALLAZGOS - PASO 1')\n",
    "print('=' * 70)\n",
    "\n",
    "print('''\n",
    "üîç INSIGHTS PRINCIPALES:\n",
    "\n",
    "1. VARIABLE OBJETIVO (Transportado):\n",
    "   - Distribuci√≥n relativamente balanceada\n",
    "   - Aproximadamente 50% en cada clase\n",
    "   - Bien para modelos de clasificaci√≥n\n",
    "\n",
    "2. VALORES FALTANTES:\n",
    "   - Algunas columnas tienen valores faltantes (revisar EDA anterior)\n",
    "   - Estrategia: Imputar con media/moda seg√∫n tipo de variable\n",
    "\n",
    "3. VARIABLES M√ÅS PROMETEDORAS:\n",
    "   - Variables num√©ricas: Edad, gastos en amenidades (Spa, Cafeteria, etc.)\n",
    "   - Variables categ√≥ricas: PlanetaOrigen, Destino, SuenoCriogenico\n",
    "   - Estas ser√°n focalizadas en el modelo\n",
    "\n",
    "4. CORRELACIONES INTERESANTES:\n",
    "   - Correlaciones bajas a moderadas con Transportado\n",
    "   - Sugiere relaciones no lineales\n",
    "   - Random Forest podr√≠a ser mejor que Regresi√≥n Log√≠stica\n",
    "\n",
    "5. PR√ìXIMOS PASOS:\n",
    "   - Imputar valores faltantes\n",
    "   - Crear nuevas caracter√≠sticas si es necesario\n",
    "   - Codificar variables categ√≥ricas\n",
    "   - Escalar variables num√©ricas\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7acffa8",
   "metadata": {},
   "source": [
    "# PASO 2: Limpieza de Datos e Ingenier√≠a de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c724496",
   "metadata": {},
   "source": [
    "## 2.1 An√°lisis Detallado de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('AN√ÅLISIS DETALLADO - VALORES FALTANTES')\n",
    "print('=' * 70)\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Agrupar faltantes por tipo de variable\n",
    "num_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "cat_cols = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print('\\nVARIABLES NUM√âRICAS CON FALTANTES:')\n",
    "for col in num_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        print(f'  {col}: {df_clean[col].isnull().sum()} ({df_clean[col].isnull().sum()/len(df_clean)*100:.2f}%)')\n",
    "\n",
    "print('\\nVARIABLES CATEG√ìRICAS CON FALTANTES:')\n",
    "for col in cat_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        print(f'  {col}: {df_clean[col].isnull().sum()} ({df_clean[col].isnull().sum()/len(df_clean)*100:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a8ad4",
   "metadata": {},
   "source": [
    "## 2.2 Estrategia de Imputaci√≥n (Justificada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('ESTRATEGIA DE IMPUTACI√ìN')\n",
    "print('=' * 70)\n",
    "\n",
    "print('''\n",
    "JUSTIFICACI√ìN POR TIPO DE VARIABLE:\n",
    "\n",
    "üìä VARIABLES NUM√âRICAS:\n",
    "   - M√©todo: MEDIA\n",
    "   - Raz√≥n: Resistente a outliers moderados, mantiene distribuci√≥n\n",
    "   - Alternativas descartadas: Mediana (menos interpretable), KNN (m√°s complejo)\n",
    "\n",
    "üìù VARIABLES CATEG√ìRICAS:\n",
    "   - M√©todo: MODA (valor m√°s frecuente)\n",
    "   - Raz√≥n: Preserva patrones de la variable, no introduce sesgo\n",
    "   - Alternativas descartadas: \"Desconocido\" (sesga modelo), Drop (pierde data)\n",
    "''')\n",
    "\n",
    "# Aplicar imputaci√≥n\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputar num√©ricas con media\n",
    "num_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "if num_cols:\n",
    "    imputer_num = SimpleImputer(strategy='mean')\n",
    "    df_clean[num_cols] = imputer_num.fit_transform(df_clean[num_cols])\n",
    "    print('\\n‚úì Variables num√©ricas imputadas con MEDIA')\n",
    "\n",
    "# Imputar categ√≥ricas con moda\n",
    "cat_cols = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if cat_cols:\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "    df_clean[cat_cols] = imputer_cat.fit_transform(df_clean[cat_cols])\n",
    "    print('‚úì Variables categ√≥ricas imputadas con MODA')\n",
    "\n",
    "# Verificar\n",
    "print(f'\\nValores faltantes despu√©s de imputaci√≥n: {df_clean.isnull().sum().sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb91b6",
   "metadata": {},
   "source": [
    "## 2.3 Ingenier√≠a de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4341ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('INGENIER√çA DE CARACTER√çSTICAS')\n",
    "print('=' * 70)\n",
    "\n",
    "print('''\n",
    "NUEVAS CARACTER√çSTICAS CREADAS:\n",
    "\n",
    "1. TotalGastos: Suma de todos los gastos en amenidades\n",
    "   Raz√≥n: Captura poder adquisitivo total del pasajero\n",
    "   \n",
    "2. EsVIP_Binary: Conversi√≥n expl√≠cita a 0/1\n",
    "   Raz√≥n: Facilita la comparaci√≥n y an√°lisis\n",
    "\n",
    "3. EdadGrupo: Categorizaci√≥n de edad en grupos\n",
    "   Raz√≥n: Captura relaciones no lineales con edad\n",
    "\n",
    "4. EsJoven: Boolean si edad < 18\n",
    "   Raz√≥n: Podr√≠a tener relaci√≥n especial con transporte\n",
    "\n",
    "5. TieneGastosAltos: Si TotalGastos > percentil 75\n",
    "   Raz√≥n: Divide a pasajeros por nivel de consumo\n",
    "''')\n",
    "\n",
    "# Crear caracter√≠sticas\n",
    "df_clean['TotalGastos'] = df_clean[['ServicioHabitacion', 'Cafeteria', 'CentroComercial', 'Spa', 'CubiertaVR']].sum(axis=1)\n",
    "\n",
    "df_clean['EsVIP'] = (df_clean['ServicioVIP'] == True).astype(int)\n",
    "\n",
    "df_clean['EdadGrupo'] = pd.cut(df_clean['Edad'], bins=[0, 18, 35, 50, 100], labels=['Ni√±o', 'Adulto', 'Mayor', 'Anciano'])\n",
    "\n",
    "df_clean['EsJoven'] = (df_clean['Edad'] < 18).astype(int)\n",
    "\n",
    "df_clean['TieneGastosAltos'] = (df_clean['TotalGastos'] > df_clean['TotalGastos'].quantile(0.75)).astype(int)\n",
    "\n",
    "print('\\n‚úì 5 nuevas caracter√≠sticas creadas exitosamente')\n",
    "print(f'\\nDataset ahora tiene {df_clean.shape[1]} columnas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f36a9",
   "metadata": {},
   "source": [
    "## 2.4 Eliminaci√≥n de Columnas sin Valor Predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('ELIMINACI√ìN DE COLUMNAS')\n",
    "print('=' * 70)\n",
    "\n",
    "print('''\n",
    "COLUMNAS A ELIMINAR Y JUSTIFICACI√ìN:\n",
    "\n",
    "1. IdPasajero: ID √∫nico, no tiene informaci√≥n predictiva\n",
    "2. Iniciales: Identificador personal, sin patr√≥n predictivo\n",
    "3. Cabina: Demasiado variada, solo ubicaci√≥n en nave\n",
    "   \n",
    "COLUMNAS A MANTENER:\n",
    "- Todas las dem√°s tienen potencial predictivo (variables, nuevas caracter√≠sticas)\n",
    "''')\n",
    "\n",
    "# Eliminar columnas\n",
    "columnas_drop = ['IdPasajero', 'Iniciales', 'Cabina']\n",
    "df_clean = df_clean.drop(columns=columnas_drop)\n",
    "\n",
    "print(f'\\n‚úì Columnas eliminadas: {columnas_drop}')\n",
    "print(f'\\nDataset final: {df_clean.shape[0]} filas √ó {df_clean.shape[1]} columnas')\n",
    "print(f'Columnas actuales: {df_clean.columns.tolist()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404b216",
   "metadata": {},
   "source": [
    "## 2.5 Validaci√≥n Final de Datos Limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('VALIDACI√ìN FINAL - PASO 2')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'\\n‚úì Sin valores faltantes: {df_clean.isnull().sum().sum() == 0}')\n",
    "print(f'‚úì Shape: {df_clean.shape}')\n",
    "print(f'‚úì Columnas: {len(df_clean.columns)}')\n",
    "print(f'\\nTipos de datos:')\n",
    "print(df_clean.dtypes)\n",
    "print(f'\\nMuestra de datos limpios:')\n",
    "display(df_clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675848b6",
   "metadata": {},
   "source": [
    "# PASO 3: Pre-procesamiento de Datos para el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca282bc",
   "metadata": {},
   "source": [
    "## 3.1 Separar Features (X) y Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('SEPARACI√ìN DE FEATURES Y TARGET')\n",
    "print('=' * 70)\n",
    "\n",
    "y = df_clean['Transportado'].astype(int)\n",
    "X = df_clean.drop(columns=['Transportado'])\n",
    "\n",
    "print(f'Target (y): {y.shape}')\n",
    "print(f'  - Distribuci√≥n: {y.value_counts().to_dict()}')\n",
    "print(f'\\nFeatures (X): {X.shape}')\n",
    "print(f'  - Columnas: {X.columns.tolist()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7651e12",
   "metadata": {},
   "source": [
    "## 3.2 One-Hot Encoding para Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('ONE-HOT ENCODING')\n",
    "print('=' * 70)\n",
    "\n",
    "# Identificar categ√≥ricas\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "print(f'Variables categ√≥ricas: {cat_cols}')\n",
    "print(f'Variables num√©ricas: {num_cols}')\n",
    "\n",
    "# One-Hot Encoding\n",
    "if len(cat_cols) > 0:\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')\n",
    "    X_cat_encoded = encoder.fit_transform(X[cat_cols])\n",
    "    X_cat_encoded = pd.DataFrame(\n",
    "        X_cat_encoded,\n",
    "        columns=encoder.get_feature_names_out(cat_cols),\n",
    "        index=X.index\n",
    "    )\n",
    "    print(f'\\n‚úì One-Hot Encoding completado: {X_cat_encoded.shape}')\n",
    "    print(f'Nuevas columnas: {X_cat_encoded.columns.tolist()[:10]}...')\n",
    "else:\n",
    "    X_cat_encoded = pd.DataFrame(index=X.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62a8f8",
   "metadata": {},
   "source": [
    "## 3.3 StandardScaler para Variables Num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('STANDARDSCALER')\n",
    "print('=' * 70)\n",
    "\n",
    "if len(num_cols) > 0:\n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = scaler.fit_transform(X[num_cols])\n",
    "    X_num_scaled = pd.DataFrame(X_num_scaled, columns=num_cols, index=X.index)\n",
    "    print(f'‚úì StandardScaler completado: {X_num_scaled.shape}')\n",
    "    print(f'\\nEjemplo de escalado (primeras 3 filas):')\n",
    "    display(X_num_scaled.head(3))\n",
    "else:\n",
    "    X_num_scaled = pd.DataFrame(index=X.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66021bc",
   "metadata": {},
   "source": [
    "## 3.4 Dataset Final Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('DATASET FINAL PREPROCESADO')\n",
    "print('=' * 70)\n",
    "\n",
    "X_processed = pd.concat([X_cat_encoded, X_num_scaled], axis=1)\n",
    "\n",
    "print(f'‚úì Shape final: {X_processed.shape}')\n",
    "print(f'‚úì Sin valores NaN: {X_processed.isnull().sum().sum() == 0}')\n",
    "print(f'\\nMuestra de datos procesados:')\n",
    "display(X_processed.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed41bc",
   "metadata": {},
   "source": [
    "# PASO 4: Entrenamiento y Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e01a98",
   "metadata": {},
   "source": [
    "## 4.1 Divisi√≥n de Datos (60% Entrenamiento, 20% Validaci√≥n, 20% Prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('DIVISI√ìN DE DATOS')\n",
    "print('=' * 70)\n",
    "\n",
    "# Primera divisi√≥n: 80% temp, 20% prueba\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Segunda divisi√≥n: 75% entrenamiento, 25% validaci√≥n\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f'Entrenamiento: {X_train.shape[0]} ({X_train.shape[0]/len(y)*100:.1f}%)')\n",
    "print(f'Validaci√≥n: {X_val.shape[0]} ({X_val.shape[0]/len(y)*100:.1f}%)')\n",
    "print(f'Prueba: {X_test.shape[0]} ({X_test.shape[0]/len(y)*100:.1f}%)')\n",
    "\n",
    "print(f'\\nDistribuci√≥n del target - Entrenamiento: {y_train.value_counts().to_dict()}')\n",
    "print(f'Distribuci√≥n del target - Validaci√≥n: {y_val.value_counts().to_dict()}')\n",
    "print(f'Distribuci√≥n del target - Prueba: {y_test.value_counts().to_dict()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9fbe5",
   "metadata": {},
   "source": [
    "## 4.2 Selecci√≥n y Justificaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df09ddf7",
   "metadata": {},
   "source": [
    "\n",
    "### Modelos Seleccionados: Random Forest + Regresi√≥n Log√≠stica\n",
    "\n",
    "#### üå≤ Random Forest\n",
    "**Ventajas:**\n",
    "- Captura relaciones NO lineales\n",
    "- Maneja bien datos con correlaciones bajas (como el nuestro)\n",
    "- Proporciona importancia de caracter√≠sticas\n",
    "- Robusto ante valores at√≠picos\n",
    "\n",
    "**Desventajas:**\n",
    "- Menos interpretable que Regresi√≥n Log√≠stica\n",
    "- Puede overfitting en datasets peque√±os\n",
    "\n",
    "#### üìä Regresi√≥n Log√≠stica  \n",
    "**Ventajas:**\n",
    "- Modelo baseline r√°pido y interpretable\n",
    "- Probabilidades calibradas\n",
    "- Excelente como comparaci√≥n\n",
    "\n",
    "**Desventajas:**\n",
    "- Asume relaciones lineales\n",
    "- Podr√≠a subperformar con relaciones complejas\n",
    "\n",
    "**Decisi√≥n:** Entrenar ambos y elegir el que mejor Accuracy tenga en validaci√≥n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ee78e",
   "metadata": {},
   "source": [
    "## 4.3 Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('ENTRENAMIENTO DE MODELOS')\n",
    "print('=' * 70)\n",
    "\n",
    "# Regresi√≥n Log√≠stica\n",
    "print('\\nEntrenando Regresi√≥n Log√≠stica...')\n",
    "import time\n",
    "start = time.time()\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_time = time.time() - start\n",
    "print(f'‚úì Completado en {lr_time:.2f}s')\n",
    "\n",
    "# Random Forest\n",
    "print('\\nEntrenando Random Forest...')\n",
    "start = time.time()\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_time = time.time() - start\n",
    "print(f'‚úì Completado en {rf_time:.2f}s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68155f",
   "metadata": {},
   "source": [
    "## 4.4 Comparaci√≥n en Conjunto de Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('EVALUACI√ìN EN VALIDACI√ìN')\n",
    "print('=' * 70)\n",
    "\n",
    "def eval_model(y_true, y_pred, model_name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f'{model_name} - Accuracy: {acc:.4f}')\n",
    "    return acc\n",
    "\n",
    "y_val_pred_lr = lr_model.predict(X_val)\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "acc_lr_val = eval_model(y_val, y_val_pred_lr, 'Regresi√≥n Log√≠stica')\n",
    "acc_rf_val = eval_model(y_val, y_val_pred_rf, 'Random Forest')\n",
    "\n",
    "# Seleccionar mejor modelo\n",
    "mejor_modelo = rf_model if acc_rf_val > acc_lr_val else lr_model\n",
    "mejor_nombre = 'Random Forest' if acc_rf_val > acc_lr_val else 'Regresi√≥n Log√≠stica'\n",
    "print(f'\\n‚úì MEJOR MODELO EN VALIDACI√ìN: {mejor_nombre}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cbfbf",
   "metadata": {},
   "source": [
    "## 4.5 Evaluaci√≥n Final en Conjunto de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20688f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('EVALUACI√ìN FINAL EN PRUEBA')\n",
    "print('=' * 70)\n",
    "\n",
    "y_test_pred = mejor_modelo.predict(X_test)\n",
    "accuracy_final = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Modelo: {mejor_nombre}')\n",
    "print(f'Accuracy: {accuracy_final:.4f} ({accuracy_final*100:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae55717c",
   "metadata": {},
   "source": [
    "## 4.6 Matriz de Confusi√≥n y Reporte Detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('MATRIZ DE CONFUSI√ìN Y M√âTRICAS')\n",
    "print('=' * 70)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f'\\nMatriz de Confusi√≥n:')\n",
    "print(cm)\n",
    "\n",
    "# Visualizar matriz\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Transportado', 'Transportado'],\n",
    "            yticklabels=['No Transportado', 'Transportado'])\n",
    "plt.title(f'Matriz de Confusi√≥n - {mejor_nombre}')\n",
    "plt.ylabel('Verdadero')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificaci√≥n\n",
    "print(f'\\nReporte Detallado de Clasificaci√≥n:')\n",
    "print(classification_report(y_test, y_test_pred, target_names=['No Transportado', 'Transportado']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee0acc",
   "metadata": {},
   "source": [
    "## 4.7 Interpretaci√≥n de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('INTERPRETACI√ìN DE RESULTADOS - PASO 4')\n",
    "print('=' * 70)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f'''\n",
    "üìä AN√ÅLISIS DEL RENDIMIENTO:\n",
    "\n",
    "‚úì Verdaderos Positivos (TP): {tp}\n",
    "  - Pasajeros correctamente identificados como Transportados\n",
    "\n",
    "‚úì Verdaderos Negativos (TN): {tn}\n",
    "  - Pasajeros correctamente identificados como No Transportados\n",
    "\n",
    "‚ö† Falsos Positivos (FP): {fp}\n",
    "  - Pasajeros predichos como Transportados pero no fueron\n",
    "\n",
    "‚ö† Falsos Negativos (FN): {fn}\n",
    "  - Pasajeros predichos como No Transportados pero s√≠ fueron\n",
    "\n",
    "üìà M√âTRICAS:\n",
    "- Accuracy: {accuracy_final:.4f} ({accuracy_final*100:.2f}%)\n",
    "- Total Errores: {fp + fn}/{len(y_test)} ({(fp+fn)/len(y_test)*100:.2f}%)\n",
    "\n",
    "üîç AN√ÅLISIS DE ERRORES:\n",
    "''')\n",
    "\n",
    "if fp > fn:\n",
    "    print(f'‚ö† El modelo SE EQUIVOCA M√ÅS en Falsos Positivos ({fp} casos)')\n",
    "    print(f'   ‚Üí Tiende a predecir \"Transportado\" demasiado a menudo')\n",
    "    print(f'   ‚Üí Recomendaci√≥n: Ajustar threshold de predicci√≥n')\n",
    "elif fn > fp:\n",
    "    print(f'‚ö† El modelo SE EQUIVOCA M√ÅS en Falsos Negativos ({fn} casos)')\n",
    "    print(f'   ‚Üí Tiende a perderse casos reales de \"Transportado\"')\n",
    "    print(f'   ‚Üí Recomendaci√≥n: Aumentar sensibilidad del modelo')\n",
    "else:\n",
    "    print(f'‚úì Errores balanceados entre FP ({fp}) y FN ({fn})')\n",
    "    print(f'   ‚Üí Buen equilibrio entre precisi√≥n y recall')\n",
    "\n",
    "# Importancia de caracter√≠sticas (si aplica)\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    print(f'\\nüéØ TOP 10 CARACTER√çSTICAS M√ÅS IMPORTANTES ({mejor_nombre}):')\n",
    "    importances = mejor_modelo.feature_importances_\n",
    "    indices = np.argsort(importances)[-10:][::-1]\n",
    "    for i, idx in enumerate(indices, 1):\n",
    "        print(f'  {i:2d}. {X_processed.columns[idx]:30s} ‚Üí {importances[idx]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e0bd3",
   "metadata": {},
   "source": [
    "# PASO 5: Generaci√≥n del Archivo de Entrega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc90e0",
   "metadata": {},
   "source": [
    "## 5.1 Cargar Datos de Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('CARGAR DATOS DE PREDICCI√ìN')\n",
    "print('=' * 70)\n",
    "\n",
    "datos_prediccion = pd.read_csv('registros_evaluacion-2.csv')\n",
    "print(f'‚úì Datos cargados: {datos_prediccion.shape}')\n",
    "print(f'Primeras filas:')\n",
    "display(datos_prediccion.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a117a11",
   "metadata": {},
   "source": [
    "## 5.2 Aplicar Limpieza Id√©ntica al Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('LIMPIEZA DE DATOS DE PREDICCI√ìN')\n",
    "print('=' * 70)\n",
    "\n",
    "df_pred = datos_prediccion.copy()\n",
    "\n",
    "# Guardar IdPasajero\n",
    "id_pasajero = df_pred['IdPasajero'].copy()\n",
    "\n",
    "# Imputar valores faltantes\n",
    "num_cols_pred = df_pred.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "cat_cols_pred = df_pred.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if num_cols_pred:\n",
    "    imputer_num_pred = SimpleImputer(strategy='mean')\n",
    "    df_pred[num_cols_pred] = imputer_num_pred.fit_transform(df_pred[num_cols_pred])\n",
    "\n",
    "if cat_cols_pred:\n",
    "    imputer_cat_pred = SimpleImputer(strategy='most_frequent')\n",
    "    df_pred[cat_cols_pred] = imputer_cat_pred.fit_transform(df_pred[cat_cols_pred])\n",
    "\n",
    "# Crear mismas caracter√≠sticas\n",
    "df_pred['TotalGastos'] = df_pred[['ServicioHabitacion', 'Cafeteria', 'CentroComercial', 'Spa', 'CubiertaVR']].sum(axis=1)\n",
    "df_pred['EsVIP'] = (df_pred['ServicioVIP'] == True).astype(int)\n",
    "df_pred['EdadGrupo'] = pd.cut(df_pred['Edad'], bins=[0, 18, 35, 50, 100], labels=['Ni√±o', 'Adulto', 'Mayor', 'Anciano'])\n",
    "df_pred['EsJoven'] = (df_pred['Edad'] < 18).astype(int)\n",
    "df_pred['TieneGastosAltos'] = (df_pred['TotalGastos'] > df_pred['TotalGastos'].quantile(0.75)).astype(int)\n",
    "\n",
    "# Eliminar mismas columnas\n",
    "df_pred = df_pred.drop(columns=['IdPasajero', 'Iniciales', 'Cabina'])\n",
    "\n",
    "print(f'‚úì Limpieza completada: {df_pred.shape}')\n",
    "print(f'‚úì Sin valores faltantes: {df_pred.isnull().sum().sum() == 0}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d54d73",
   "metadata": {},
   "source": [
    "## 5.3 Aplicar Preprocesamiento Id√©ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('PREPROCESAMIENTO DE DATOS DE PREDICCI√ìN')\n",
    "print('=' * 70)\n",
    "\n",
    "# Separar categ√≥ricas y num√©ricas\n",
    "cat_cols_pred = df_pred.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols_pred = df_pred.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# One-Hot Encoding\n",
    "X_cat_pred = pd.DataFrame(index=df_pred.index)\n",
    "if cat_cols_pred:\n",
    "    encoder_pred = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')\n",
    "    X_cat_pred = encoder_pred.fit_transform(df_pred[cat_cols_pred])\n",
    "    X_cat_pred = pd.DataFrame(X_cat_pred, columns=encoder_pred.get_feature_names_out(cat_cols_pred), index=df_pred.index)\n",
    "\n",
    "# StandardScaler\n",
    "X_num_pred = pd.DataFrame(index=df_pred.index)\n",
    "if num_cols_pred:\n",
    "    scaler_pred = StandardScaler()\n",
    "    X_num_pred = scaler_pred.fit_transform(df_pred[num_cols_pred])\n",
    "    X_num_pred = pd.DataFrame(X_num_pred, columns=num_cols_pred, index=df_pred.index)\n",
    "\n",
    "# Combinar\n",
    "X_processed_pred = pd.concat([X_cat_pred, X_num_pred], axis=1)\n",
    "\n",
    "# Ajustar columnas a match del entrenamiento\n",
    "if X_processed_pred.shape[1] < X_processed.shape[1]:\n",
    "    missing_cols = set(X_processed.columns) - set(X_processed_pred.columns)\n",
    "    for col in missing_cols:\n",
    "        X_processed_pred[col] = 0\n",
    "    X_processed_pred = X_processed_pred[X_processed.columns]\n",
    "\n",
    "print(f'‚úì Preprocesamiento completado: {X_processed_pred.shape}')\n",
    "print(f'‚úì Coincide con entrenamiento: {X_processed_pred.shape == X_processed.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18a586",
   "metadata": {},
   "source": [
    "## 5.4 Realizar Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('REALIZANDO PREDICCIONES')\n",
    "print('=' * 70)\n",
    "\n",
    "y_predicciones = mejor_modelo.predict(X_processed_pred)\n",
    "\n",
    "print(f'‚úì Predicciones realizadas: {len(y_predicciones)}')\n",
    "print(f'\\nDistribuci√≥n de predicciones:')\n",
    "unique, counts = np.unique(y_predicciones, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    label = 'Transportado' if u == 1 else 'No Transportado'\n",
    "    print(f'  {label}: {c} ({c/len(y_predicciones)*100:.1f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accb95c",
   "metadata": {},
   "source": [
    "## 5.5 Generar Archivo de Entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('GENERANDO ARCHIVO DE ENTREGA')\n",
    "print('=' * 70)\n",
    "\n",
    "# Crear DataFrame\n",
    "entrega = pd.DataFrame({\n",
    "    'IdPasajero': id_pasajero,\n",
    "    'Transportado': y_predicciones\n",
    "})\n",
    "\n",
    "# Guardar\n",
    "archivo_salida = 'predicciones_transportado.csv'\n",
    "entrega.to_csv(archivo_salida, index=False)\n",
    "\n",
    "print(f'‚úì Archivo guardado: {archivo_salida}')\n",
    "print(f'‚úì Dimensiones: {entrega.shape}')\n",
    "print(f'\\nPrimeras 10 filas:')\n",
    "display(entrega.head(10))\n",
    "print(f'\\n√öltimas 10 filas:')\n",
    "display(entrega.tail(10))\n",
    "\n",
    "print(f'\\n' + '='*70)\n",
    "print('‚úÖ GENERACI√ìN DE ENTREGA COMPLETADA')\n",
    "print('='*70)\n",
    "print(f'Total de predicciones: {len(entrega)}')\n",
    "print(f'Transportados: {(entrega[\"Transportado\"] == 1).sum()}')\n",
    "print(f'No Transportados: {(entrega[\"Transportado\"] == 0).sum()}')\n",
    "print(f'Archivo listo para env√≠o: {archivo_salida}')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
